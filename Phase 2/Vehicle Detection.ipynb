{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* 1. **Introduction**\n",
    "* 2. **Step 1: Creating the SVM Classifier Model**\n",
    "    * 2.1 Basic Imports\n",
    "    * 2.2 2.2 Selecting training features from input images (HoG and color features)\n",
    "    * 2.3 Feature Extraction from dataset\n",
    "    * 2.4 Load training data from dataset\n",
    "    * 2.5 SVM Classifier training and Saving the model\n",
    "* 3.**Step 2: Vehicle Detection**\n",
    "    * 3.1 Loading the trained model\n",
    "    * 3.2 Sliding window search with different window scales\n",
    "    * 3.3 Merging the bounding boxes using heat maps and thresholding\n",
    "    * 3.4 Display bounding boxes on the images\n",
    "* 4. **Using our Code to Detect Vehicles on Sample Videos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer vision and machine learning often attempt to replicate tasks that most of us take for granted, identifying other vehicles on the road is one of those tasks. In this notebook we aim to detect vehicles on the road using a HOG-based SVM for finding and tracking vehicles in a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Step 1: Creating the SVM Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage import label\n",
    "from moviepy.editor import VideoFileClip\n",
    "import queue\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import os\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Selecting training features from input images (HoG and color features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1A: Select required train features (HOG and color features)\"\"\"\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    \"\"\"\n",
    "    Return the hog features of the given input image\n",
    "    Call with two outputs if vis==True\"\"\"\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                                  visualize=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, \n",
    "                       visualize=vis, feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(16, 16)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to compute color histogram features \n",
    "## NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Feature Extraction from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1B: Define a function to extract features from a list of images\"\"\"\n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel='ALL',\n",
    "                        spatial_feat=False, hist_feat=False, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)   \n",
    "\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Load training data from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1C: Load images from the dataset\"\"\"\n",
    "def read_images(vehicles_dir,non_vehicles_dir):\n",
    "    #Read cars and not-cars images\n",
    "    # images are divided up into vehicles and non-vehicles\n",
    "    cars = []\n",
    "    notcars = []\n",
    "\n",
    "    # Read vehicle images\n",
    "    images = glob.iglob(vehicles_dir + '/**/*.png', recursive=True)\n",
    "\n",
    "    for image in images:\n",
    "            cars.append(image)\n",
    "\n",
    "    # Read non-vehicle images\n",
    "    images = glob.iglob(non_vehicles_dir + '/**/*.png', recursive=True)\n",
    "\n",
    "    for image in images:\n",
    "            notcars.append(image)\n",
    "    \n",
    "    return cars, notcars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 SVM Classifier training and Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier():\n",
    "    colorspace = 'YUV' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "    spatial_size=(32, 32)\n",
    "    hist_bins=32\n",
    "    \n",
    "    t=time.time()\n",
    "    \n",
    "    cars,notcars=read_images('./dataset/vehicles/','./dataset/non-vehicles/')\n",
    "    car_features = extract_features(cars, cspace=colorspace, orient=orient, \n",
    "                            pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, hist_bins=hist_bins)\n",
    "    notcar_features = extract_features(notcars, cspace=colorspace, orient=orient, \n",
    "                            pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, hist_bins=hist_bins)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to extract HOG features...')\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64) \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    \n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "    \n",
    "    \n",
    "    # Split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_X, y, test_size=0.15, random_state=rand_state)\n",
    "    \n",
    "    print('Using:',orient,'orientations',pix_per_cell,\n",
    "        'pixels per cell and', cell_per_block,'cells per block')\n",
    "    print('Feature vector length:', len(X_train[0]))\n",
    "    \n",
    "    # Use a linear SVC X_scaler\n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "    \n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "    # Check the prediction time for a single sample\n",
    "    t=time.time()\n",
    "    n_predict = 10\n",
    "    print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "    print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "    \n",
    "    \n",
    "    \"\"\"Save the training model\"\"\"\n",
    "    \n",
    "    #Pickle the data as it takes a lot of time to generate it\n",
    "    \n",
    "    data_file = './svc_pickle.p'\n",
    "    \n",
    "    if not os.path.isfile(data_file):\n",
    "        with open(data_file, 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'svc': svc,\n",
    "                    'scaler': X_scaler,\n",
    "                    'orient': orient,\n",
    "                    'pix_per_cell': pix_per_cell,\n",
    "                    'cell_per_block': cell_per_block,\n",
    "                    'spatial_size': spatial_size,\n",
    "                    'hist_bins': hist_bins\n",
    "                    \n",
    "                },\n",
    "                pfile, pickle.HIGHEST_PROTOCOL) \n",
    "    print('Data saved in pickle file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Vehicle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Classifier parameters...\n",
      "Loading is done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"2A: Load the training model\"\"\"\n",
    "print('Loading Classifier parameters...')\n",
    "dist_pickle = pickle.load( open(\"svc_pickle.p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"spatial_size\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]\n",
    "\n",
    "print('Loading is done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Sliding window search with different window scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select various color spaces\n",
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    \"\"\"\n",
    "    Convert the image from one color space to the other\n",
    "    \"\"\"\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    if conv == 'RGB2HLS':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    if conv == 'RGB2HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    if conv == 'Gray':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if conv == 'RGB2YUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, vis_bboxes = False):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    xstart = int(img.shape[1]/5)\n",
    "    xstop = img.shape[1]\n",
    "    img_tosearch = img[ystart:ystop, xstart:xstop,:]\n",
    "    ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YUV')\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (int(imshape[1]/scale), int(imshape[0]/scale)))\n",
    "\n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    rectangles = []\n",
    "\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            \n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3)).reshape(1, -1)\n",
    "            \n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "\n",
    "            test_features = X_scaler.transform(hog_features)   \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1 or vis_bboxes == True:\n",
    "                xbox_left = int(xleft*scale)\n",
    "                ytop_draw = int(ytop*scale)\n",
    "                win_draw = int(window*scale)\n",
    "                rectangles.append(((xbox_left+xstart, ytop_draw+ystart),(xbox_left+win_draw+xstart,ytop_draw+win_draw+ystart)))\n",
    "                              \n",
    "    return rectangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Merging the bounding boxes using heat maps and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"2C: Merge the bounding boxes using heat maps and thresholding \"\"\"\n",
    "\n",
    "def get_rectangles(image, scales = [1, 1.5, 2, 2.5, 3], \n",
    "                   ystarts = [400, 400, 450, 450, 460], \n",
    "                   ystops = [528, 550, 620, 650, 700]):\n",
    "    out_rectangles = []\n",
    "    for scale, ystart, ystop in zip(scales, ystarts, ystops):\n",
    "        rectangles = find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "        if len(rectangles) > 0:\n",
    "            out_rectangles.append(rectangles)\n",
    "    out_rectangles = [item for sublist in out_rectangles for item in sublist] \n",
    "    return out_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Display bounding boxes on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    img_copy = np.copy(img)\n",
    "    result_rectangles = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        area = (bbox[1][1] - bbox[0][1]) * (bbox[1][0] - bbox[0][0])\n",
    "        if area > 40 * 40:\n",
    "            result_rectangles.append(bbox)\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img_copy, bbox[0], bbox[1], (0,255,0), 6)\n",
    "    # Return the image\n",
    "    return result_rectangles, img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the test images\"\"\"\n",
    "#Read cars and not-cars images\n",
    "\n",
    "#Data folders\n",
    "test_images_dir = './test_images/'\n",
    "\n",
    "# images are divided up into vehicles and non-vehicles\n",
    "test_images = []\n",
    "\n",
    "images = glob.glob(test_images_dir + '*.jpg')\n",
    "\n",
    "for image in images:\n",
    "        test_images.append(mpimg.imread(image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionInfo():\n",
    "    def __init__(self):\n",
    "        self.max_size = 10\n",
    "        self.old_bboxes = queue.Queue(self.max_size) \n",
    "        self.heatmap = np.zeros_like(test_images[0][:, :, 0])\n",
    "        \n",
    "    def get_heatmap(self):\n",
    "        self.heatmap = np.zeros_like(test_images[0][:, :, 0])\n",
    "        if self.old_bboxes.qsize() == self.max_size:\n",
    "            for bboxes in list(self.old_bboxes.queue):\n",
    "                self.heatmap = add_heat(self.heatmap, bboxes)\n",
    "                #self.heatmap = apply_threshold(self.heatmap, 2)\n",
    "            self.heatmap = apply_threshold(self.heatmap, 20)\n",
    "        return self.heatmap\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return label(self.get_heatmap())\n",
    "        \n",
    "    def add_bboxes(self, bboxes):\n",
    "        if len(bboxes) < 1:\n",
    "            return\n",
    "        if self.old_bboxes.qsize() == self.max_size:\n",
    "            self.old_bboxes.get()\n",
    "        self.old_bboxes.put(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=-1\n",
    "def find_vehicles(image):\n",
    "    global i\n",
    "    global labels\n",
    "    i=i+1\n",
    "    if i%2==0:\n",
    "        bboxes = get_rectangles(image) \n",
    "        detection_info.add_bboxes(bboxes)\n",
    "        labels = detection_info.get_labels()\n",
    "        if len(labels) == 0:\n",
    "            result_image = image\n",
    "        else:\n",
    "            bboxes, result_image = draw_labeled_bboxes(image,labels)\n",
    "    \n",
    "    else:\n",
    "        bboxes, result_image = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    \n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Using our Code to Detect Vehicles on Sample Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ./output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main\"\"\"    \n",
    "detection_info = DetectionInfo()\n",
    "detection_info.old_heatmap = np.zeros_like(test_images[0][:, :, 0])\n",
    "project_video_path = \"./project_video.mp4\"\n",
    "project_video_output = \"./output_video.mp4\"\n",
    "\n",
    "project_video = VideoFileClip(project_video_path)\n",
    "white_clip = project_video.fl_image(find_vehicles)\n",
    "white_clip.write_videofile(project_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
